{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "#import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#import PyQt5\n",
    "import random\n",
    "import operator\n",
    "%matplotlib inline\n",
    "\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD(lambda) Value Function Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "class BlackJack:\n",
    "    def __init__(self, MAX_EPISODES=500000):\n",
    "        self.env = gym.make('Blackjack-v0')\n",
    "        self.MAX_EPISODES = MAX_EPISODES\n",
    "        self.ALPHA = 0.5\n",
    "        self.GAMMA = 0.95\n",
    "        self.LAMBDA = 0.5\n",
    "        \n",
    "        # State values\n",
    "        self.v = dict({})\n",
    "        for p_hand in range(self.env.observation_space[0].n):\n",
    "            for d_card in range(self.env.observation_space[1].n):\n",
    "                for useable_ace in range(self.env.observation_space[2].n):\n",
    "                    string = str(p_hand) + '_' + str(d_card) + '_' + str(useable_ace)\n",
    "                    self.v[string] = 0 # Initiate to 0\n",
    "\n",
    "        # Eligibility traces\n",
    "        self.e = dict({})\n",
    "        for p_hand in range(self.env.observation_space[0].n):\n",
    "            for d_card in range(self.env.observation_space[1].n):\n",
    "                for useable_ace in range(self.env.observation_space[2].n):\n",
    "                    string = str(p_hand) + '_' + str(d_card) + '_' + str(useable_ace)\n",
    "                    self.e[string] = 0 # Initiate to 0\n",
    "            \n",
    "    def action(self, player_hand):\n",
    "        \"\"\"\n",
    "        NB: What about the usable ace?\n",
    "        \"\"\"\n",
    "        probs = [0.8, 0.2] if player_hand > 18 else [0.2, 0.8]\n",
    "        action = np.random.choice(np.arange(2), p=probs)\n",
    "        return action\n",
    "\n",
    "    def run_episode(self):\n",
    "        new_s = self.env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            s = new_s\n",
    "            s_key = str(s[0]) + '_' + str(s[1]) + '_' + str(1*s[2])\n",
    "            \n",
    "            # Choose action and take a step\n",
    "            a = self.action(s[0])\n",
    "            new_s, r, done, _ = self.env.step(a)\n",
    "            new_s_key = str(new_s[0]) + '_' + str(new_s[1]) + '_' + str(1*new_s[2])\n",
    "            \n",
    "            # Update eligibilities\n",
    "            self.e.update((x, y * self.LAMBDA * self.GAMMA) for x, y in self.e.items())\n",
    "            self.e[s_key] += 1\n",
    "            \n",
    "            # Update value function according to \n",
    "            # the td-error and update their eligibilities.\n",
    "            td_error = r + self.GAMMA * self.v[new_s_key] - self.v[s_key]\n",
    "            self.v[s_key] += self.ALPHA * td_error * self.e[s_key]\n",
    "                 \n",
    "    def value_iteration(self):\n",
    "        for episode in range(self.MAX_EPISODES):\n",
    "            if episode % 10000 == 0:\n",
    "                print(f\"Value Iteration {episode}\")\n",
    "            self.run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bj = BlackJack()\n",
    "bj.value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "for key, value in bj.v.items():\n",
    "    if (int('2_10_1'[-1])) & (int(key.split('_')[0]) > 11) & (int(key.split('_')[0]) < 22) & (int(key.split('_')[1]) < 12):  # Usable ace\n",
    "        X.append(int(key.split('_')[0]))\n",
    "        Y.append(int(key.split('_')[1]))\n",
    "        Z.append(value)        \n",
    "        \n",
    "plotx, ploty, = np.meshgrid(np.linspace(np.min(X),np.max(X),10),\\\n",
    "                           np.linspace(np.min(Y),np.max(Y),10))\n",
    "plotz = interp.griddata((X,Y),Z,(plotx,ploty),method='linear')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(plotx,ploty,plotz,cstride=1,rstride=1,cmap='viridis')  # or 'hot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake8x8-v0')\n",
    "new_s = env.reset()\n",
    "env.step(1)\n",
    "#env.action_space.contains(3)\n",
    "#env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward View SARSA(lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "class BlackJackSARSA:\n",
    "    def __init__(self, MAX_EPISODES=500000):\n",
    "        self.env = gym.make('Blackjack-v0')\n",
    "        self.MAX_EPISODES = MAX_EPISODES\n",
    "        self.ALPHA = 0.5\n",
    "        self.GAMMA = 0.95\n",
    "        self.LAMBDA = 0.5\n",
    "        self.EPS = 0.9\n",
    "        \n",
    "        # State-action values\n",
    "        self.q = dict({})\n",
    "        for p_hand in range(self.env.observation_space[0].n):\n",
    "            for d_card in range(self.env.observation_space[1].n):\n",
    "                for usable_ace in range(self.env.observation_space[2].n):\n",
    "                    for action in range(self.env.action_space.n):\n",
    "                        key = (p_hand, d_card, usable_ace, action)\n",
    "                        self.q[key] = 0 # Initiate to 0\n",
    "            \n",
    "    def action(self, player_hand):\n",
    "        \"\"\"\n",
    "        NB: What about the usable ace?\n",
    "        \"\"\"\n",
    "        probs = [0.8, 0.2] if player_hand > 18 else [0.2, 0.8]\n",
    "        action = np.random.choice(np.arange(2), p=probs)\n",
    "        return action\n",
    "\n",
    "    def greedy_action(self, state):\n",
    "        q_sub = {key: val for key, val in self.q.items() if key[0:len(state)] == state}\n",
    "        return max(q_sub.items(), key=operator.itemgetter(1))[0][-1]\n",
    "\n",
    "    def epsilon_greedy(self, state):\n",
    "        if np.random.random() >= self.EPS:\n",
    "            return self.greedy_action(state)\n",
    "\n",
    "        return self.env.action_space.sample()    \n",
    "    \n",
    "    def run_episode(self):\n",
    "        # Eligibility traces\n",
    "        e = dict({})\n",
    "        for p_hand in range(self.env.observation_space[0].n):\n",
    "            for d_card in range(self.env.observation_space[1].n):\n",
    "                for usable_ace in range(self.env.observation_space[2].n):\n",
    "                    for action in range(self.env.action_space.n):\n",
    "                        key = (p_hand, d_card, usable_ace, action)\n",
    "                        e[key] = 0 # Initiate to 0\n",
    "        \n",
    "        new_s = self.env.reset()\n",
    "        new_a = random.sample([0, 1], k=1)[0]\n",
    "        done = False\n",
    "        while not done:\n",
    "            s = new_s\n",
    "            a = new_a\n",
    "            #s_a_key = str(s[0]) + '_' + str(s[1]) + '_' + str(1*s[2]) + '_' + str(a)\n",
    "            s_a_key = s + (a,)\n",
    "            \n",
    "            # Take action a\n",
    "            new_s, r, done, _ = self.env.step(a)\n",
    "            \n",
    "            # Choose new action from S'\n",
    "            new_a = self.epsilon_greedy(new_s)\n",
    "            new_s_a_key = new_s + (new_a,)\n",
    "            #new_s_a_key = str(new_s[0]) + '_' + str(new_s[1]) + '_' + str(1*new_s[2]) + '_' + str(new_a)\n",
    "\n",
    "            # Calculate TD error\n",
    "            delta = r + self.GAMMA * self.q[new_s_a_key] - self.q[s_a_key]\n",
    "            \n",
    "            # Update eligibilities\n",
    "            e.update((x, y * self.LAMBDA * self.GAMMA) for x, y in e.items())\n",
    "            e[s_a_key] += 1\n",
    "            \n",
    "            # Update q values\n",
    "            self.q.update((x, y + self.ALPHA * delta * e[x]) for x, y in self.q.items())\n",
    "\n",
    "    def policy_iteration(self, n_episodes=1000):\n",
    "        for episode in range(n_episodes):\n",
    "            if episode % 1000 == 0:\n",
    "                print(f\"Policy Iteration {episode}\")\n",
    "            self.run_episode() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjsarsa = BlackJackSARSA()\n",
    "bjsarsa.policy_iteration(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjsarsa.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    display(display_animation(anim, default_mode='loop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FrozenLake\n",
    "https://gym.openai.com/envs/FrozenLake8x8-v0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "class FZSARSA:\n",
    "    def __init__(self, MAX_EPISODES=500000):\n",
    "        self.env = gym.make('FrozenLake8x8-v0')\n",
    "        self.MAX_EPISODES = MAX_EPISODES\n",
    "        self.ALPHA = 0.5\n",
    "        self.GAMMA = 0.95\n",
    "        self.LAMBDA = 0.5\n",
    "        self.EPS = 0.9\n",
    "        \n",
    "        # State-action values\n",
    "        self.q = dict({})\n",
    "        for s in range(self.env.observation_space.n):\n",
    "            for action in range(self.env.action_space.n):\n",
    "                key = (s, action)\n",
    "                self.q[key] = 0 # Initiate to 0\n",
    "            \n",
    "    def greedy_action(self, state):\n",
    "        q_sub = {key: val for key, val in self.q.items() if key[0] == state}\n",
    "        return max(q_sub.items(), key=operator.itemgetter(1))[0][-1]\n",
    "\n",
    "    def epsilon_greedy(self, state):\n",
    "        if np.random.random() >= self.EPS:\n",
    "            return self.greedy_action(state)\n",
    "\n",
    "        return self.env.action_space.sample()    \n",
    "    \n",
    "    def run_episode(self, d=False):\n",
    "        print('HEY')\n",
    "        \n",
    "        # Eligibility traces\n",
    "        e = dict({})\n",
    "        for s in range(self.env.observation_space.n):\n",
    "            for action in range(self.env.action_space.n):\n",
    "                key = (s, action)\n",
    "                e[key] = 0 # Initiate to 0\n",
    "        \n",
    "        new_s = self.env.reset()\n",
    "        new_a = random.sample(range(4), k=1)[0]\n",
    "        done = False\n",
    "        \n",
    "        if d:\n",
    "            img = plt.imshow(self.env.render(mode='rgb_array')) # only call this once\n",
    "            \n",
    "        while not done:    \n",
    "            s = new_s\n",
    "            a = new_a\n",
    "            s_a_key = (s,) + (a,)\n",
    "            \n",
    "            if d:            \n",
    "                img.set_data(self.env.render(mode='rgb_array')) # just update the data\n",
    "            \n",
    "            # Take action a\n",
    "            new_s, r, done, _ = self.env.step(a)\n",
    "            \n",
    "            # Choose new action from S'\n",
    "            if d:\n",
    "                new_a = self.greedy_action(new_s)                \n",
    "            else:\n",
    "                new_a = self.epsilon_greedy(new_s)\n",
    "            new_s_a_key = (new_s,) + (new_a,)\n",
    "\n",
    "            # Calculate TD error\n",
    "            delta = r + self.GAMMA * self.q[new_s_a_key] - self.q[s_a_key]\n",
    "            \n",
    "            # Update eligibilities\n",
    "            e.update((x, y * self.LAMBDA * self.GAMMA) for x, y in e.items())\n",
    "            e[s_a_key] += 1\n",
    "            \n",
    "            # Update q values\n",
    "            self.q.update((x, y + self.ALPHA * delta * e[x]) for x, y in self.q.items())    \n",
    "        \n",
    "    def policy_iteration(self, n_episodes=1000):\n",
    "        for episode in range(n_episodes):\n",
    "            if episode % 100 == 0:\n",
    "                print(f\"Policy Iteration {episode}\")\n",
    "            self.run_episode() \n",
    "            self.env.close()        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Iteration 0\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 100\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 200\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 300\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 400\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 500\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 600\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 700\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 800\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "Policy Iteration 900\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n",
      "HEY\n"
     ]
    }
   ],
   "source": [
    "fzsarsa = FZSARSA()\n",
    "fzsarsa.policy_iteration(1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fzsarsa.run_episode(d=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Run a demo of the environment\n",
    "observation = env.reset()\n",
    "cum_reward = 0\n",
    "frames = []\n",
    "for t in range(5000):\n",
    "    # Render into buffer. \n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "env.close()\n",
    "display_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
