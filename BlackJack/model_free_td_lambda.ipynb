{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import PyQt5\n",
    "import random\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD(lambda) Value Function Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "class BlackJack:\n",
    "    def __init__(self, MAX_EPISODES=500000):\n",
    "        self.env = gym.make('Blackjack-v0')\n",
    "        self.MAX_EPISODES = MAX_EPISODES\n",
    "        self.ALPHA = 0.5\n",
    "        self.GAMMA = 0.95\n",
    "        self.LAMBDA = 0.5\n",
    "        \n",
    "        # State values\n",
    "        self.v = dict({})\n",
    "        for p_hand in range(self.env.observation_space[0].n):\n",
    "            for d_card in range(self.env.observation_space[1].n):\n",
    "                for useable_ace in range(self.env.observation_space[2].n):\n",
    "                    string = str(p_hand) + '_' + str(d_card) + '_' + str(useable_ace)\n",
    "                    self.v[string] = 0 # Initiate to 0\n",
    "\n",
    "        # Eligibility traces\n",
    "        self.e = dict({})\n",
    "        for p_hand in range(self.env.observation_space[0].n):\n",
    "            for d_card in range(self.env.observation_space[1].n):\n",
    "                for useable_ace in range(self.env.observation_space[2].n):\n",
    "                    string = str(p_hand) + '_' + str(d_card) + '_' + str(useable_ace)\n",
    "                    self.e[string] = 0 # Initiate to 0\n",
    "            \n",
    "    def action(self, player_hand):\n",
    "        \"\"\"\n",
    "        NB: What about the usable ace?\n",
    "        \"\"\"\n",
    "        probs = [0.8, 0.2] if player_hand > 18 else [0.2, 0.8]\n",
    "        action = np.random.choice(np.arange(2), p=probs)\n",
    "        return action\n",
    "\n",
    "    def run_episode(self):\n",
    "        new_s = self.env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            s = new_s\n",
    "            s_key = str(s[0]) + '_' + str(s[1]) + '_' + str(1*s[2])\n",
    "            \n",
    "            # Choose action and take a step\n",
    "            a = self.action(s[0])\n",
    "            new_s, r, done, _ = self.env.step(a)\n",
    "            new_s_key = str(new_s[0]) + '_' + str(new_s[1]) + '_' + str(1*new_s[2])\n",
    "            \n",
    "            # Update eligibilities\n",
    "            self.e.update((x, y * self.LAMBDA * self.GAMMA) for x, y in self.e.items())\n",
    "            self.e[s_key] += 1\n",
    "            \n",
    "            # Update value function according to \n",
    "            # the td-error and update their eligibilities.\n",
    "            td_error = r + self.GAMMA * self.v[new_s_key] - self.v[s_key]\n",
    "            self.v[s_key] += self.ALPHA * td_error * self.e[s_key]\n",
    "                 \n",
    "    def value_iteration(self):\n",
    "        for episode in range(self.MAX_EPISODES):\n",
    "            if episode % 10000 == 0:\n",
    "                print(f\"Value Iteration {episode}\")\n",
    "            self.run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Iteration 0\n",
      "Value Iteration 10000\n",
      "Value Iteration 20000\n",
      "Value Iteration 30000\n",
      "Value Iteration 40000\n",
      "Value Iteration 50000\n",
      "Value Iteration 60000\n",
      "Value Iteration 70000\n",
      "Value Iteration 80000\n",
      "Value Iteration 90000\n",
      "Value Iteration 100000\n",
      "Value Iteration 110000\n",
      "Value Iteration 120000\n",
      "Value Iteration 130000\n",
      "Value Iteration 140000\n",
      "Value Iteration 150000\n",
      "Value Iteration 160000\n",
      "Value Iteration 170000\n",
      "Value Iteration 180000\n",
      "Value Iteration 190000\n",
      "Value Iteration 200000\n",
      "Value Iteration 210000\n",
      "Value Iteration 220000\n",
      "Value Iteration 230000\n",
      "Value Iteration 240000\n",
      "Value Iteration 250000\n",
      "Value Iteration 260000\n",
      "Value Iteration 270000\n",
      "Value Iteration 280000\n",
      "Value Iteration 290000\n",
      "Value Iteration 300000\n",
      "Value Iteration 310000\n",
      "Value Iteration 320000\n",
      "Value Iteration 330000\n",
      "Value Iteration 340000\n",
      "Value Iteration 350000\n",
      "Value Iteration 360000\n",
      "Value Iteration 370000\n",
      "Value Iteration 380000\n",
      "Value Iteration 390000\n",
      "Value Iteration 400000\n",
      "Value Iteration 410000\n",
      "Value Iteration 420000\n",
      "Value Iteration 430000\n",
      "Value Iteration 440000\n",
      "Value Iteration 450000\n",
      "Value Iteration 460000\n",
      "Value Iteration 470000\n",
      "Value Iteration 480000\n",
      "Value Iteration 490000\n"
     ]
    }
   ],
   "source": [
    "bj = BlackJack()\n",
    "bj.value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x123926110>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "for key, value in bj.v.items():\n",
    "    if (int('2_10_1'[-1])) & (int(key.split('_')[0]) > 11) & (int(key.split('_')[0]) < 22) & (int(key.split('_')[1]) < 12):  # Usable ace\n",
    "        X.append(int(key.split('_')[0]))\n",
    "        Y.append(int(key.split('_')[1]))\n",
    "        Z.append(value)        \n",
    "        \n",
    "plotx, ploty, = np.meshgrid(np.linspace(np.min(X),np.max(X),10),\\\n",
    "                           np.linspace(np.min(Y),np.max(Y),10))\n",
    "plotz = interp.griddata((X,Y),Z,(plotx,ploty),method='linear')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(plotx,ploty,plotz,cstride=1,rstride=1,cmap='viridis')  # or 'hot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward View SARSA(lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "class BlackJackSARSA:\n",
    "    def __init__(self, MAX_EPISODES=500000):\n",
    "        self.env = gym.make('Blackjack-v0')\n",
    "        self.MAX_EPISODES = MAX_EPISODES\n",
    "        self.ALPHA = 0.5\n",
    "        self.GAMMA = 0.95\n",
    "        self.LAMBDA = 0.5\n",
    "        \n",
    "        # State values\n",
    "        self.q = dict({})\n",
    "        for p_hand in range(self.env.observation_space[0].n):\n",
    "            for d_card in range(self.env.observation_space[1].n):\n",
    "                for useable_ace in range(self.env.observation_space[2].n):\n",
    "                    for action in range(self.env.action_space.n)\n",
    "                        string = str(p_hand) + '_' + str(d_card) + '_' + str(useable_ace) + '_' + str(action)\n",
    "                        self.q[string] = 0 # Initiate to 0\n",
    "\n",
    "        # Eligibility traces\n",
    "        self.e = dict({})\n",
    "        for p_hand in range(self.env.observation_space[0].n):\n",
    "            for d_card in range(self.env.observation_space[1].n):\n",
    "                for useable_ace in range(self.env.observation_space[2].n):\n",
    "                    for action in range(self.env.action_space.n)\n",
    "                        string = str(p_hand) + '_' + str(d_card) + '_' + str(useable_ace) + '_' + str(action)\n",
    "                        self.e[string] = 0 # Initiate to 0\n",
    "            \n",
    "    def action(self, player_hand):\n",
    "        \"\"\"\n",
    "        NB: What about the usable ace?\n",
    "        \"\"\"\n",
    "        probs = [0.8, 0.2] if player_hand > 18 else [0.2, 0.8]\n",
    "        action = np.random.choice(np.arange(2), p=probs)\n",
    "        return action\n",
    "\n",
    "    def greedy_action(self, state):\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def epsilon_greedy(self, state):\n",
    "        if np.random.random() >= self.eps:\n",
    "            return self.greedy_action(state)\n",
    "\n",
    "        return self.env.action_space.sample()    \n",
    "    \n",
    "    def run_episode(self):\n",
    "        new_s = self.env.reset()\n",
    "        a = random.sample([0, 1], k=1)[0]\n",
    "        done = False\n",
    "        while not done:\n",
    "            s = new_s\n",
    "            s_a_key = str(s[0]) + '_' + str(s[1]) + '_' + str(1*s[2]) + '_' + str(a)\n",
    "\n",
    "            # Take action a\n",
    "            new_s, r, done, _ = self.env.step(a)\n",
    "            new_s_a_key = str(new_s[0]) + '_' + str(new_s[1]) + '_' + str(1*new_s[2]) + '_' + str(a)\n",
    "            \n",
    "            # Choose new action from S'\n",
    "            a = self.epsilon_greedy(new_s)\n",
    "            \n",
    "            # Update eligibilities\n",
    "            self.e.update((x, y * self.LAMBDA * self.GAMMA) for x, y in self.e.items())\n",
    "            self.e[s_key] += 1\n",
    "            \n",
    "            # Update value function according to \n",
    "            # the td-error and update their eligibilities.\n",
    "            td_error = r + self.GAMMA * self.v[new_s_key] - self.v[s_key]\n",
    "            self.v[s_key] += self.ALPHA * td_error * self.e[s_key]\n",
    "                 \n",
    "    def value_iteration(self):\n",
    "        for episode in range(self.MAX_EPISODES):\n",
    "            if episode % 10000 == 0:\n",
    "                print(f\"Value Iteration {episode}\")\n",
    "            self.run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
