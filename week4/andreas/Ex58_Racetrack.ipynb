{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.8: Racetrack (programming) \n",
    "Consider driving a race car around a turn like those shown in Figure 5.5. You want to go as fast as possible, but not so fast as to run off the track. In our simplified racetrack, the car is at one of a discrete set of grid positions, the cells in the diagram. \n",
    "* The velocity is also discrete, a number of grid cells moved horizontally and vertically per time step. \n",
    "* The actions are increments to the velocity components. Each may be changed by +1, −1, or 0 in one step, for a total of nine actions. \n",
    "* Both velocity components are restricted to be nonnegative and less than 5, and they cannot both be zero except at the starting line. \n",
    "* Each episode begins in one of the randomly selected start states with both velocity components zero and ends when the car crosses the finish line. \n",
    "* The rewards are −1 for each step until the car crosses the finish line. \n",
    "* If the car hits the track boundary, it is moved back to a random position on the starting line, both velocity components are reduced to zero, and the episode continues. \n",
    "* Before updating the car’s location at each time step, check to see if the projected path of the car intersects the track boundary. If it intersects the finish line, the episode ends; if it intersects anywhere else, the car is considered to have hit the track boundary and is sent back to the starting line. \n",
    "* To make the task more challenging, with probability 0.1 at each time step the velocity increments are both zero, independently of the intended increments. \n",
    "\n",
    "Apply a Monte Carlo control method to this task to compute the optimal policy from each starting state. Exhibit several trajectories following the optimal policy (but turn the noise off for these trajectories).\n",
    "\n",
    "<img src=\"racetrack.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "\n",
    "CELL_TYPE_WALL = 0\n",
    "CELL_TYPE_TRACK = 1\n",
    "CELL_TYPE_GOAL = 2\n",
    "CELL_TYPE_START = 3\n",
    "\n",
    "class RaceTrack:\n",
    "    def __init__(self, track, max_vel=5, min_vel=-5):\n",
    "        self.track = track\n",
    "        self.wall_cells = np.argwhere(track == CELL_TYPE_WALL)\n",
    "        self.goal_cells = np.argwhere(track == CELL_TYPE_GOAL)\n",
    "        self.start_cells = np.argwhere(track == CELL_TYPE_START)\n",
    "        self.max_vel = max_vel\n",
    "        self.min_vel = min_vel\n",
    "        self.colors = ['black', 'white', 'yellow', 'red']\n",
    "    \n",
    "    @classmethod\n",
    "    def from_csv(cls, file_path):\n",
    "        \n",
    "        file_path = os.path.join(os.getcwd(), file_path)\n",
    "        \n",
    "        track = genfromtxt(file_path, delimiter=',')\n",
    "\n",
    "        return cls(track) \n",
    "    \n",
    "    def actions(self, state):\n",
    "        actions = [[a_x, a_y] for a_x in range(-1,2) for a_y in range(-1,2)]\n",
    "        legal_actions = []\n",
    "        \n",
    "        _, _, v_x, v_y = state\n",
    "        \n",
    "        # Discard illegal actions\n",
    "        for a in actions:\n",
    "            a_x, a_y = a\n",
    "            # Cannot go above speed limit in any x direction\n",
    "            if v_x + a_x < self.min_vel or v_x + a_x > self.max_vel:\n",
    "                continue\n",
    "            # Cannot go above speed limit in any y direction\n",
    "            if v_y + a_y < self.min_vel or v_y + a_y > self.max_vel:\n",
    "                continue\n",
    "            # Cannot noop\n",
    "            if v_x + a_x == 0 and v_y + a_y == 0:\n",
    "                continue\n",
    "            legal_actions.append(a)\n",
    "        return legal_actions\n",
    "    \n",
    "    def apply_action(self, state, action):\n",
    "        y, x, v_y, v_x = state\n",
    "        a_y, a_x = action\n",
    "        \n",
    "        v_y_new = v_y + a_y\n",
    "        v_x_new = v_x + a_x\n",
    "                \n",
    "        path = projected_path((y, x), (v_y_new, v_x_new))\n",
    "        \n",
    "        terminated = self.crossed_finish_line(path)\n",
    "            \n",
    "        if not terminated and self.crossed_track_boundary(path):\n",
    "            start_cell_idx = np.random.choice(self.track.start_cells.shape[0], 1, replace=False)\n",
    "            start_cell = self.track.start_cells[start_cell_idx[0], :]\n",
    "            start_state = np.concatenate([start_cell, [0,0]])     \n",
    "        \n",
    "        y_new = y + v_y\n",
    "        x_new = x + v_x\n",
    "        \n",
    "        return np.array([y_new, x_new, v_y_new, v_x_new]), -1, terminated\n",
    "        \n",
    "    def projected_path(self, state, speed):\n",
    "        # TODO: Should we only consider end state directly?\n",
    "        y, x = state\n",
    "        v_y, v_x = speed\n",
    "        \n",
    "        y_new = y + v_y\n",
    "        x_new = x + v_x\n",
    "        \n",
    "        path = []        \n",
    "        for dy in range(min(y, y_new), max(y, y_new) + 1):\n",
    "            for dx in range(min(x, x_new), max(x, x_new) + 1):\n",
    "                path.append((dy,dx))\n",
    "        return path\n",
    "        \n",
    "    def crossed_track_boundary(self, projected_path):        \n",
    "        for cell in projected_path:   \n",
    "            y, x = cell\n",
    "            if y < 0 or y > self.track.shape[0] or x < 0 or x > self.track.shape[1] or cell in self.wall_cells:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def crossed_finish_line(self, projected_path):\n",
    "        for cell in projected_path:\n",
    "            if cell in self.goal_cells:\n",
    "                return True\n",
    "        return False  \n",
    "        \n",
    "    def draw(self, car_cell=None, path=[]):\n",
    "        fig=plt.figure(figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "        \n",
    "        im = plt.imshow(self.track, cmap=ListedColormap(self.colors), origin='lower', interpolation='none', animated=True)\n",
    "        \n",
    "        def rect(pos, edgecolor='k', facecolor='none'):\n",
    "            r = plt.Rectangle(pos, 1,1, facecolor=facecolor, edgecolor=edgecolor, linewidth=2)\n",
    "            plt.gca().add_patch(r)\n",
    "            \n",
    "        for i in range(self.track.shape[0]):\n",
    "            for j in range(self.track.shape[1]):\n",
    "                rect((j-0.5,i-0.5))\n",
    "                \n",
    "        if path:\n",
    "            for cell in path:\n",
    "                rect((cell[1]-0.5, cell[0]-0.5), edgecolor='g')\n",
    "        \n",
    "        if car_cell:\n",
    "            rect((car_cell[1]-0.5, car_cell[0]-0.5), edgecolor='g', facecolor='g')\n",
    "            \n",
    "        plt.gca().invert_yaxis()\n",
    "        return im\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = RaceTrack.from_csv(\"../racetracks/map1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 8), (4, 9), (4, 10), (5, 8), (5, 9), (5, 10), (6, 8), (6, 9), (6, 10)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = rt.projected_path((6,8),(-2,2))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10caf9da0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rt.draw((6,8),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class OffPolicyMonteCarloAgent:\n",
    "    def __init__(self, track, gamma = 1, n_episodes=100000):\n",
    "        self.track = track\n",
    "        self.gamma = gamma\n",
    "        self.n_episodes = n_episodes\n",
    "                \n",
    "        # Initialize Q values and C values\n",
    "        state_track_y_range = track.track.shape[0]\n",
    "        state_track_x_range = track.track.shape[1]\n",
    "        state_y_vel_range = track.max_vel - track.min_vel + 1\n",
    "        state_x_vel_range = track.max_vel - track.min_vel + 1\n",
    "        action_y_acc_range = 3 # -1, 0, +1\n",
    "        action_x_acc_range = 3 # -1, 0, +1\n",
    "        \n",
    "        # State-action (Q) space\n",
    "        # Initial state-action values\n",
    "        q_shape = (state_track_y_range, state_track_x_range, state_y_vel_range, state_x_vel_range, action_y_acc_range, action_x_acc_range)\n",
    "        self.Q = np.zeros(q_shape)\n",
    "        \n",
    "        # State (C) space\n",
    "        c_shape = (state_track_y_range, state_track_x_range, state_y_vel_range, state_x_vel_range)\n",
    "        # Initial C values\n",
    "        self.C = np.zeros(c_shape)\n",
    "        \n",
    "        # Initial Policy\n",
    "        # For each state: choose a random action from the set of allowed actions in the given state\n",
    "        self.pi = np.empty(c_shape, dtype=object)\n",
    "        for y in range(state_track_y_range):\n",
    "            for x in range(state_track_x_range):\n",
    "                for v_y in range(self.track.min_vel, self.track.max_vel + 1):\n",
    "                    for v_x in range(self.track.min_vel, self.track.max_vel + 1):\n",
    "                        self.pi[y, x, v_y, v_x] = random.choice(self.track.actions([y, x, v_y, v_x]))\n",
    "                        \n",
    "    def solve_track(self):\n",
    "        it = 0\n",
    "        while True:\n",
    "            b = self.pi\n",
    "            \n",
    "            # Generate an episode using soft policy b\n",
    "            S, A, R = self.generate_episode(b)\n",
    "            G = 0\n",
    "            W = 1\n",
    "            print('Episode n:{}\\t Steps required:{}'.format(it, len(S))\n",
    "            for t in range(len(S) - 1, -1, -1):\n",
    "                  G = self.gamma * G + R[t]\n",
    "                  self.C[]\n",
    "                  \n",
    "            \n",
    "    def generate_episode(self, pi):\n",
    "        S = []\n",
    "        A = []\n",
    "        R = []\n",
    "        \n",
    "        # Select the initial state randomly\n",
    "        start_cell_idx = np.random.choice(self.track.start_cells.shape[0], 1, replace=False)\n",
    "        start_cell = self.track.start_cells[start_cell_idx[0], :]\n",
    "        start_state = np.concatenate([start_cell, [0,0]])\n",
    "        S.append(start_state)\n",
    "        \n",
    "        t = 0\n",
    "        while True:\n",
    "            a = pi[S[t]]\n",
    "            A.append(a)\n",
    "        \n",
    "            state, reward, terminated = self.track.apply_action(S[t], A[t])\n",
    "            R.append(reward)\n",
    "            \n",
    "            if terminated:\n",
    "                break\n",
    "            S.append(state)\n",
    "            t += 1\n",
    "        return S, A, R\n",
    "    \n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OffPolicyMonteCarloAgent(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.generate_episode(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
